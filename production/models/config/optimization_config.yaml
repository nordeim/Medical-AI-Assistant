# Model Optimization Configuration

quantization:
  enabled: true
  method: "dynamic"  # dynamic, static, qat
  precision: "int8"
  calibration_samples: 100
  per_channel_quantization: true
  symmetric_quantization: true

pruning:
  enabled: true
  method: "magnitude"  # magnitude, structured, lottery_ticket
  sparsity: 0.5
  gradual_pruning: true
  pruning_schedule: "polynomial"
  target_sparsity: 0.7

graph_optimization:
  enabled: true
  optimization_level: "O2"  # O0, O1, O2, O3
  constant_folding: true
  dead_code_elimination: true
  operator_fusion: true
  convert_to_onnx: true

batch_optimization:
  max_batch_size: 32
  dynamic_batching: true
  batch_timeout_ms: 50
  pad_to_max_batch: false

# Optimization Profiles
optimization_profiles:
  fast_inference:
    quantization: true
    pruning: false
    graph_optimization: true
    batch_size: 1
    target_latency_ms: 50
  balanced:
    quantization: true
    pruning: true
    graph_optimization: true
    batch_size: 8
    target_latency_ms: 200
  memory_efficient:
    quantization: true
    pruning: true
    compression: true
    batch_size: 4
    target_memory_mb: 256
  maximum_accuracy:
    quantization: false
    pruning: false
    graph_optimization: true
    batch_size: 16
    target_accuracy_retention: 0.99

# Performance Targets
performance_targets:
  inference_latency:
    edge_devices: 100  # ms
    cloud_production: 200  # ms
    real_time: 50  # ms
  memory_usage:
    edge_devices: 50   # MB
    cloud_production: 512  # MB
    mobile: 25  # MB
  model_size:
    edge_devices: 10   # MB
    mobile: 5   # MB
    cloud: 100  # MB

# Hardware-Specific Optimization
hardware_optimization:
  cpu:
    vectorization: true
    threading: true
    cache_optimization: true
  gpu:
    enabled: false  # Set to true if GPU available
    batch_processing: true
    memory_optimization: true
  tpu:
    enabled: false  # Set to true if TPU available
    mixed_precision: true

# Benchmarking Configuration
benchmarking:
  enabled: true
  warmup_runs: 10
  benchmark_runs: 100
  measure_memory: true
  measure_throughput: true
  export_results: true

# Optimization Constraints
constraints:
  max_model_size_mb: 100
  max_inference_latency_ms: 500
  min_accuracy_retention: 0.95
  max_memory_usage_gb: 4